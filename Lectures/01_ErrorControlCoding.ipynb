{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.   Error control coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is error control coding?\n",
    "\n",
    "![Communication system](img/CommBlockDiagram.png){width=40%}\n",
    "\n",
    "* The second main task of coding: error control \n",
    "* Protect information against channel errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual information and error control\n",
    "\n",
    "* Mutual information $I(X,Y)$ = the information transmitted on the channel\n",
    "* Why do we still need error control?\n",
    "\n",
    "Example: consider the following BSC channel (p = 0.01, $p(x_1) = 0.5$, $p(x_2)=0.5$):\n",
    "\n",
    "![Binary symmetric channel (BSC) ](img/BSC.png){width=25%}\n",
    "\n",
    "* The receiver would like to know the source messages \n",
    "    * In absence of communication, the uncertainty is $H(X) = 1$ bit/msg\n",
    "    * With communication, the uncertainty is $H(X|Y) \\approx 0.081$ bit/msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual information and error control\n",
    "\n",
    "* The reduction in  uncertainty due to communication = mutual information\n",
    "    * $I(X,Y) = H(X) - H(X|Y) = \\approx 0.919$ bit/msg\n",
    "    \n",
    "* Even though we have large I(X,Y), about $1\\%$ of all bits are erroneuos\n",
    "    * Imagine downloading a file, but having $1\\%$ wrong bits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Why is error control needed?\n",
    "\n",
    "* In most communications it is required that *all* bits are received correctly\n",
    "    * Not $1\\%$ errors, not $0.1\\%$, not $0.0001\\%$. **None!**\n",
    "\n",
    "* But that is not possible unless the channel is ideal.\n",
    "\n",
    "* So what do to? Error control coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling the errors on the channel\n",
    "\n",
    "* We consider only binary channels (symbols = $\\left\\lbrace 0,1 \\right\\rbrace$\n",
    "* An error = a bit is changed from 0 to 1 or viceversa\n",
    "* Errors can appear:\n",
    "    * **independently**: each bit on its own\n",
    "    * in **packets of errors**: groups of errors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling the errors on the channel\n",
    "\n",
    "* Changing the value of a bit = modulo-2 sum with 1\n",
    "* Value of a bit remains the same = modulo-2 sum with 0\n",
    "    \n",
    "![Channel error model](img/ChannelErrorModel.png){width=50%}\n",
    "\n",
    "* Channel model we use (simple):\n",
    "    * The transmitted sequence is summed modulo-2 with an **error sequence**\n",
    "    * Where the error sequence is 1, there is a bit error\n",
    "    * Where the error sequence is 0, there is no error\n",
    "$$\\mathbf{r} = \\mathbf{c} + \\mathbf{e}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error detection and error correction\n",
    "\n",
    "Binary error correction:\n",
    "\n",
    "* For binary channels, know the location of error => fix error by inverting bit\n",
    "* Locating error = correcting error\n",
    "\n",
    "Two possibilities in practice:\n",
    "\n",
    "* **Error detection**: find out if there is any error in the received sequence\n",
    "    * don't know exactly where, so cannot correct the bits, but can discard whole sequence\n",
    "    * perhaps ask the sender to retransmit (examples: TCP/IP, internet communication etc)\n",
    "    * easier to do\n",
    "* **Error correction**: find out exactly which bits have errors, if any\n",
    "    * can correct all errored bits by inverting them\n",
    "    * useful when can't retransmit (data is stored: on HDD, AudioCD etc.)\n",
    "    * harder to do than mere detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is error control coding?\n",
    "\n",
    "The process of error control:\n",
    "\n",
    "1. Want to send a sequence of $k$ bits = **information word**\n",
    "$$\\mathbf{i} = i_1i_2...i_k$$\n",
    "\n",
    "2. For each possible information word, the coder assigns a **codeword** of length $n > k$:\n",
    "$$\\mathbf{c} = c_1c_2...c_n$$\n",
    "\n",
    "3. The codeword is sent on the channel instead of the original information word\n",
    "\n",
    "4. The receiver receives a sequence $\\hat{\\mathbf{c}} \\approx \\mathbf{c}$, with possible errors:\n",
    "$$\\hat{\\mathbf{c}} = \\hat{c_1}\\hat{c_2}...\\hat{c_n}$$\n",
    "\n",
    "5. The decoding algorithm detects/corrects the errors in $\\hat{\\mathbf{c}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions\n",
    "\n",
    "* An **error correcting code** is an association between the set of all possible information words to a set of codewords\n",
    "    * Each possible information word $\\mathbf{i}$ has a certain codeword $\\mathbf{c}$\n",
    "* The association can be done:\n",
    "    * randomly: codewords are selected and associated randomly to the information words\n",
    "    * based on a certain rule: the codeword is computed with some algorithm from the information word\n",
    "\n",
    "* A code is a **block code** if it operates with words of *fixed size*\n",
    "    * Size of information word $\\mathbf{i} = k$, size of codeword $\\mathbf{c} = n$, $n > k$\n",
    "    * Otherwise it is a *non-block code*\n",
    "    \n",
    "* A code is **linear** if any linear combination of codewords is also a codeword\n",
    "\n",
    "* The **coding rate** of a code is:\n",
    "$$R = k/n$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions\n",
    "\n",
    "* A code $C$ is an **$t$-error-detecting** code if it is able to *detect* $t$ errors\n",
    "\n",
    "* A code $C$ is an **$t$-error-correcting** code if it is able to *correct* $t$ errors\n",
    "\n",
    "* Examples: at blackboard (random code, parity bit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intuitive example: parity bits\n",
    "\n",
    "* Add parity bit to a 8-bit long information word, before sending on a channel\n",
    "    * coding rate $R = 8/9$\n",
    "    * can detect 1 error in a 9-bit codeword\n",
    "    * cannot correct error (don't know where it is located)\n",
    "    \n",
    "* Add more parity bits to be able to locate the error\n",
    "    * Example at blackboard\n",
    "    * coding rate $R = 8/12$\n",
    "    * can detect and correct 1 error in a 9-bit codeword"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intuitive example: repetition code\n",
    "\n",
    "* Example from laboratory 4:\n",
    "    * want to send a $k$-bit information word\n",
    "    * send codeword = the information word repeated 5 times\n",
    "    * coding rate $R = k/n = 1/5$\n",
    "    * can detect and correct 2 errors, and maybe even more \n",
    "    if they do not affect the same bit\n",
    "    * not as efficient as other codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redundancy\n",
    "\n",
    "* Because $k < n$, we introduce **redundancy**\n",
    "    * to transmit $k$ bits of information we actually send more bits ($n$) \n",
    "    \n",
    "* Error control coding adds redundancy, while source coding (Chapter III) aims to reduce redundancy\n",
    "    * but redundancy is added in a controlled way, with a purpose\n",
    "    \n",
    "* In practice:\n",
    "    1. First perform source coding, eliminating redundancy in representation of data\n",
    "    2. Then perform error control coding, adding redundancy for protection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shannon's noisy channel theorem (second theorem, channel coding theorem)\n",
    "\n",
    "* A coding rate is called **achievable** for a channel if, for that rate, there exists a coding and decoding\n",
    "algorithm guaranteed to correct all possible errors on the channel\n",
    "\n",
    "#### Shannon's noisy channel coding theorem (second theorem)\n",
    "For a given channel, all rates below capacity $R < C$ are achievable. All rates\n",
    "above capacity, $R > C$, are not achievable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Channel coding theorem explained\n",
    "\n",
    "In layman terms:\n",
    "\n",
    "* For all coding rates $R<C$, there is a way to recover the transmitted data perfectly (decoding algorithm will detect and correct\n",
    "all errors)\n",
    "* For all coding rates $R>C$, there is no way to recover the transmitted data perfectly\n",
    "\n",
    "Example:\n",
    "\n",
    "* Send binary digits (0,1) on a BSC channel with capacity 0.7 bits/message\n",
    "* For any coding rate $R < 0.7$ there exist error correction codes that allow perfect recovery\n",
    "    * i.e. for every 7 bits of data coding adds slightly more than 3 bits, on average => $R < \\frac{7}{7+3}$\n",
    "* With less than 3 bits for every 7 bits of data => impossible to recover all the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideas behind channel coding theorem\n",
    "\n",
    "* The rigorous proof of the theorem is too complex to present\n",
    "* Key ideas of the proof:\n",
    "    * Use very long information words, $k \\to \\infty$\n",
    "    * Use random codes, compute the probability of having error after decoding\n",
    "    * If $R < C$, *in average for all possible codes*, the probability of error after decoding goes to 0\n",
    "    * If the average for all codes goes to 0, there exists at least on code better than the average\n",
    "    * That is the code we should use\n",
    "    \n",
    "* !! **The theorem does not tell what code to use**, only that some code exists\n",
    "* There is no hint of how to actually find the code\n",
    "* Except general principles:\n",
    "    * using longer information words is better\n",
    "    * random codewords are generally good\n",
    "    \n",
    "* In practice, cannot use infinitely long codewords, so will only get a *good enough* code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practical scenario\n",
    "\n",
    "Practical ideas for error correcting codes:\n",
    "\n",
    "* If a codeword $\\mathbf{c_1}$ is received with errors and becomes identical to another codeword $\\mathbf{c_2}$ ==> cannot detect any errors\n",
    "    * Receiver will think it received a correct codeword $c_2$ and the information word was $\\mathbf{i_2}$, but actually it was $\\mathbf{i_1}$\n",
    "* We want codewords as different as possible from each other\n",
    "* How to measure this difference?\n",
    "* Hamming distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hamming distance\n",
    "\n",
    "* The **Hamming distance** of two binary sequences $a$, $b$ of length $n$ = the total number\n",
    "of bit differences between them\n",
    "$$d_H(a, b) = \\sum_{i=1}^N a_i \\bigoplus b_i$$\n",
    "\n",
    "* We need at least $d_H(a, b)$ bit changes to convert one sequence into another\n",
    "\n",
    "* It satisfies the 3 properties of a metric function:\n",
    "    1. $d(a,b) \\geq 0 \\forall a,b$, with $d(a,b) = 0 \\Leftrightarrow a = b$\n",
    "    2. $d(a,b) = d(b,a), \\forall a,b$\n",
    "    3. $d(a,c) \\leq d(a,b) + d(b,c), \\forall a,b,c$\n",
    "\n",
    "* The **minimum Hamming distance of a code**, ${d_H}_{min}$ = the minimum Hamming distance\n",
    "between any two codewords $\\mathbf{c_1}$ and $\\mathbf{c_2}$\n",
    "\n",
    "* Example at blackboard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest-neighbor decoding\n",
    "\n",
    "Coding:\n",
    "\n",
    "* Design a code with large ${d_H}_{min}$\n",
    "* Send a codeword $\\mathbf{c}$ of the code\n",
    "    \n",
    "Decoding:\n",
    "\n",
    "* Receive a word $\\mathbf{r}$, that may have errors\n",
    "\n",
    "* Error detecting: \n",
    "    * check if $r$ is part of the codewords of the code $C$:\n",
    "    * if $r$ is part of the code, decide that there have been no errors\n",
    "    * if $r$ is not a codeword, decide that there have been errors\n",
    "\n",
    "* Error correcting:\n",
    "    * choose codeword **nearest** to the received $\\mathbf{r}$, in terms of Hamming distance\n",
    "    * (if $\\mathbf{r}$ is a codeword, leave unchanged)\n",
    "    * this is known as **nearest-neighbor decoding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of nearest neighbor decoding\n",
    "\n",
    "Theorem:\n",
    "\n",
    "If the minimum Hamming distance of a code is ${d_H}_{min}$:\n",
    "\n",
    "1. the code can *detect* up to **${d_H}_{min} - 1$** errors\n",
    "2. the code can *correct* up to **$\\left\\lfloor \\frac{{d_H}_{min} - 1}{2} \\right\\rfloor$** errors using nearest-neighbor decoding\n",
    "\n",
    "Consequence:\n",
    "\n",
    "* It is good to have ${d_H}_{min}$ as large as possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of nearest neighbor decoding\n",
    "\n",
    "Proof:\n",
    "\n",
    "1. at least ${d_H}_{min}$ binary changes are needed to change one codeword into another, ${d_H}_{min} - 1$ is not enough => the errors are detected\n",
    "2. the received word $\\mathbf{r}$ is closer to the original codeword than to any other codeword => nearest-neighbor algorithm will find the correct one\n",
    "    * because $\\left\\lfloor \\frac{{d_H}_{min} - 1}{2} \\right\\rfloor$ = less than half the distance to another codeword\n",
    "\n",
    "Note: if the number of errors is higher, can fail:\n",
    "\n",
    "* Detection failure: decide that there were no errors, even if they were (more than ${d_H}_{min} - 1$)\n",
    "* Correction failure: choose a wrong codeword\n",
    "\n",
    "Example: blackboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear block codes\n",
    "\n",
    "* A code is a **block code** if it operates with words of *fixed size*\n",
    "    * Size of information word $\\mathbf{i} = k$, size of codeword $\\mathbf{c} = n$, $n > k$\n",
    "    * Otherwise it is a *non-block code*\n",
    "    \n",
    "* A code is **linear** if any linear combination of codewords is also a codeword\n",
    "\n",
    "* A code is called **systematic** if the codeword contains all the information bits explicitly, unaltered\n",
    "    * coding merely adds supplementary bits besides the information bits\n",
    "    * codeword has two parts: the information bits and the parity bits\n",
    "    * example: parity bit added after the information bits\n",
    "    \n",
    "* Otherwise the code is called **non-systematic**\n",
    "    * the information bits are not explicitly visible in the codeword\n",
    "\n",
    "* Example: at blackboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator matrix \n",
    "\n",
    "* All codewords for a linear block code can be generated via a matrix multiplication:\n",
    "$$\\mathbf{i} \\cdot [G] = \\mathbf{c}$$\n",
    "\n",
    "![Codeword construction with generator matrix](img/GeneratorMatrix.png){width=50%}\n",
    "\n",
    "* $[G]$ = **generator matrix** of size $k \\times n$\n",
    "\n",
    "* All operations are done in modulo-2 arithmetic:\n",
    "    * $0 \\oplus 0 = 0$, $0 \\oplus 1 = 1$, $1 \\oplus 0 = 1$, $1 \\oplus 1 = 0$\n",
    "    * multiplications as usual\n",
    "    \n",
    "* Row-wise interpretation:\n",
    "    * $\\mathbf{c}$ = a linear combination of rows in $[G]$\n",
    "    * The rows of $[G]$ = a *basis* for the linear code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parity check matrix\n",
    "\n",
    "* How to check if a binary word is a codeword or not\n",
    "* Every $k \\times n$ generator matrix $[G]$ has complementary matrix $[H]$ such that\n",
    "$$0 = [H] \\cdot [G]^T$$\n",
    "\n",
    "* For every codeword $\\mathbf{c}$ generated with $[G]$:\n",
    "$$\\boxed{ 0 = [H] \\cdot \\mathbf{c}^T }$$\n",
    "\n",
    "* because:\n",
    "$$\\mathbf{i} \\cdot [G] = \\mathbf{c}$$\n",
    "$$[G]^T \\cdot \\mathbf{i}^T = \\mathbf{c}^T$$\n",
    "$$[H] \\cdot \\mathbf{c}^T = [H] \\cdot [G]^T \\cdot \\mathbf{i}^T = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parity check matrix\n",
    "\n",
    "* $[H]$ is the **parity-check matrix**, size = $(n-k) \\times n$\n",
    "* $[G]$ and $[H]$ are related, one can be deduced from the other\n",
    "* The resulting vector $z = [H] \\cdot [c]^T$ is the **syndrome**\n",
    "* All codewords generated with $[G]$ will produce $0$ when multiplied with $[H]$\n",
    "* All binary sequences that are not codewords will produce $\\neq 0$ when multiplied with $[H]$\n",
    "\n",
    "* Column-wise interpretation of multiplication:\n",
    "\n",
    "![Codeword checking with parity-check matrix](img/ParityCheckMatrix.png){width=30%}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [G] and [H] for systematic codes\n",
    "\n",
    "* For systematic codes, [G] and [H] have special forms\n",
    "* Generator matrix\n",
    "    * first part = identity matrix\n",
    "    * second part = some matrix $Q$\n",
    "$$[G]_{k \\times n} = [I_{k \\times k} \\;\\; Q_{k \\times (n-k)}]$$\n",
    "\n",
    "* Parity-check matrix\n",
    "    * first part = same Q, transposed\n",
    "    * second part = identity matrix\n",
    "$$[H]_{(n-k) \\times n} = [Q^T_{(n-k) \\times k} \\;\\; I_{(n-k) \\times (n-k)}]$$\n",
    "\n",
    "* Can easily compute one from the other\n",
    "\n",
    "* Example at blackboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation as parity bits\n",
    "\n",
    "* The additional bits added by coding are just parity bits\n",
    "\n",
    "* Generator matrix $[G]$ creates the codeword as:\n",
    "    * first part = information bits (systematic code, first part of $[G]$ is identity matrix)\n",
    "    * additional bits = combinations of information bits = *parity bits*\n",
    "\n",
    "* Parity-check matrix $[H]$ checks if parity bits correspond to information bits\n",
    "    * if all are ok, the syndrome $\\mathbf{z} = 0$ \n",
    "    * otherwise the syndrome $\\mathbf{z} \\neq 0$ \n",
    "\n",
    "* This is all just parity bits!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syndrome-based error detection\n",
    "\n",
    "Syndrome-based error *detection* for linear block codes:\n",
    "\n",
    "1. generate codewords with generator matrix:\n",
    "$$\\mathbf{i} \\cdot [G] = \\mathbf{c}$$\n",
    "\n",
    "2. send codeword $\\mathbf{c}$ on the channel\n",
    "3. random error word $\\mathbf{e}$ is applied on the channel\n",
    "4. receive word $\\mathbf{r} = \\mathbf{c} \\oplus \\mathbf{e}$\n",
    "\n",
    "5. compute **syndrome** of $\\mathbf{r}$:\n",
    "$$\\mathbf{z} = [H] \\cdot \\mathbf{r}^T$$\n",
    "\n",
    "6. Decide:\n",
    "    * If $\\mathbf{z} = 0$ => $\\mathbf{r}$ has no errors\n",
    "    * If $\\mathbf{z} \\neq 0$ => $\\mathbf{r}$ has errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syndrome-based error correction\n",
    "\n",
    "Syndrome-based error *correction* for linear block codes:\n",
    "\n",
    "* $\\mathbf{z} \\neq 0$ => $\\mathbf{r}$ has errors, we need to locate them\n",
    "\n",
    "* The syndrome is the effect only of the error word:\n",
    "$$\\mathbf{z} = [H] \\cdot \\mathbf{r}^T = [H] \\cdot (\\mathbf{c}^T \\oplus \\mathbf{e}^T) = [H] \\cdot \\mathbf{e}^T$$\n",
    "\n",
    "7. Create a **syndrome lookup table**:\n",
    "    * for every possible error word $\\mathbf{e}$, compute the syndrome $\\mathbf{z} = [H] \\cdot \\mathbf{e}^T$\n",
    "    * start with error words with 1 error (most likely), then with 2 errors (less likely), and so on\n",
    "\n",
    "8. Locate the syndrome $\\mathbf{z}$ in the table, read the corresponding error word $\\mathbf{\\hat{e}}$\n",
    "\n",
    "9. Find the correct word:\n",
    "    * adding the error word again will invert the errored bits back to the originals\n",
    "$$\\mathbf{\\hat{c}} = \\mathbf{r}  \\oplus \\mathbf{\\hat{e}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "Example: at blackboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditions on [H] for error detection and correction\n",
    "\n",
    "Error detection:\n",
    "\n",
    "* To detect a single error: every column of $[H]$ must be non-zero\n",
    "* To detect two error: sum of any two columns of $[H]$ cannot be zero\n",
    "    * that means all columns are different\n",
    "* To detect $n$ errors: sum of any $n$ or less columns of $[H]$ cannot be zero\n",
    "\n",
    "Error correction (using syndrome-based decoding):\n",
    "\n",
    "* To correct a single error: all columns of $[H]$ are different\n",
    "    * so the syndromes, for a single error, are all different\n",
    "* To correct $n$ errors: sum of any $n$ or less columns of $[H]$ are all different\n",
    "    * much more difficult to obtain than for decoding\n",
    "\n",
    "Rearranging the columns of $[H]$ (the order of bits in the codeword) does not affect performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hamming codes\n",
    "\n",
    "* Simple class of linear error-correcting codes\n",
    "\n",
    "* Definition: a **Hamming code** is a linear block code where the columns of $[H]$\n",
    "are *the binary representation of all numbers from 1 to $2^r-1$*, $\\forall r \\geq 2$\n",
    "\n",
    "* Example (blackboard): (7,4) Hamming code\n",
    "\n",
    "* Systematic: arrange the $r$ columns with a single 1 to the right, forming identity matrix\n",
    "    * Can compute generator matrix $[G]$\n",
    "    \n",
    "* Non-systematic: columns in natural order\n",
    "    * no significant difference from systematic case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Properties of Hamming codes\n",
    "\n",
    "* From definition of $[H]$ (systematic) it follows:\n",
    "    1. Codeword has length $n = 2^r - 1$\n",
    "    2. $r$ bits are parity bits\n",
    "    3. $k = 2^r-r-1$ bits are information bits\n",
    "\n",
    "* Same for non-systematic, but bits are arranged differently\n",
    "\n",
    "* Notation: **(n,k) Hamming code**\n",
    "    * n = codeword length = $2^r-1$, \n",
    "    * k = number of information bits  = $2^r - r - 1$\n",
    "    * Example: (7,4) Hamming code, (15,11) Hamming code, $(127,120)$ Hamming code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Properties of Hamming codes\n",
    "\n",
    "* Can detect two errors\n",
    "\t* All columns are different => can detect 2 errors\n",
    "\t* Sum of two columns equal to a third => cannot correct 3\n",
    "\n",
    "**OR**\n",
    "\n",
    "* Can correct one error\n",
    "\t* All columns are different => can correct 1 error\n",
    "\t* Sum of two columns equal to a third => cannot correct 2\n",
    "\t* Non-systematic: syndrome = error position\n",
    "\n",
    "* But not simultaneously!\n",
    "    * same non-zero syndrome can be obtained with 1 or 2 errors, can't distinguish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SECDED Hamming codes\n",
    " \n",
    "* Add an additional parity bit to differentiate the two cases\n",
    "    * = sum of all $n$ bits of the codeword\n",
    "\n",
    "* Compute syndrome of the received word *without the additional parity bit*\n",
    "\t* If 1 error happened: syndrome is non-zero, parity bit does not match\n",
    "\t* If 2 errors happened: syndrome is non-zero, parity bit matches (the two errors cancel out)\n",
    "\t* If 3 errors happened: same as 1, can't differentiate\n",
    "\n",
    "* Now can simultaneously differentiate between:\n",
    "    * 1 error: perform correction\n",
    "    * 2 errors: detect, but do not perform correction\n",
    "    \n",
    "* If correction is never attempted, can detect up to 3 errors\n",
    "    * minimum Hamming distance = 4 (no proof)\n",
    "    * don't know if 1 error or more, so can't try correction\n",
    "    \n",
    "* Known as SECDED Hamming codes\n",
    "    * **S**ingle **E**rror **C**orrection - **D**ouble **E**rror **D**etection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding SECDED Hamming codes\n",
    "\n",
    "\n",
    "Decoding with detection and correction\n",
    "\n",
    "1. Compute syndrome of received word without the additional parity bit\n",
    "2. If zero, no error\n",
    "3. If non-zero, check parity bit:\n",
    "    a. If does not match => one error => perform correction\n",
    "    b. If does match => two errors => do not correct\n",
    "    \n",
    "Decoding with detection only\n",
    "\n",
    "1. Compute syndrome of received word, also check additional parity bit\n",
    "2. If syndrome is zero and parity bit is ok => no error\n",
    "3. If syndrome non-zero or parity bit does not match => 1 or 2 or 3 errors have happened, do not correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary until now\n",
    "\n",
    "* Systematic codes: information bits + parity bits\n",
    "* Generator matrix: use to generate codeword\n",
    "$$\\mathbf{i} \\cdot [G] = \\mathbf{c}$$\n",
    "* Parity-check matrix: use to check if a codeword\n",
    "$$0 = [H] \\cdot \\mathbf{c}^T$$\n",
    "* Syndrome:\n",
    "$$\\mathbf{z} = [H] \\cdot \\mathbf{r}^T$$\n",
    "* Syndrome-based error detection: syndrome non-zero\n",
    "* Syndrome-based error correction: lookup table\n",
    "* Hamming codes: $[H]$ contains all numbers $1 ... 2^r - 1$\n",
    "* SECDED Hamming codes: add an extra parity bit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cyclic codes\n",
    "\n",
    "Definition: **cyclic codes** are a particular class of linear block codes\n",
    "for which *every cyclic shift of a codeword is also a codeword*\n",
    "\n",
    "* Cyclic shift: cyclic rotation of a sequence of bits (any direction)\n",
    "\n",
    "* Are a particular class of linear block codes, so all the theory up to now still applies\n",
    "    * they have a generator matrix, parity check matrix etc.\n",
    "    \n",
    "* But they can be implemented more efficient than general linear block codes (e.g. Hamming)\n",
    "\n",
    "* Used **everywhere** under the common name **CRC** (**C**yclic **R**edundancy **C**heck)\n",
    "    * Network communications (Ethernet), data storage in Flash memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary polynomials\n",
    "\n",
    "* Every binary sequence corresponds to a polynomial with binary coefficients:\n",
    "$$10010111 \\rightarrow X^7 \\oplus X^4 \\oplus X^2 \\oplus X \\oplus 1$$\n",
    "\n",
    "(From now on, by \"codeword\" we also mean the corresponding polynomial)\n",
    "\n",
    "* Can perform all operations with these polynomials:\n",
    "    * addition, multiplication, division etc. (examples)\n",
    "\n",
    "* There are efficient circuits for performing multiplications\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Circuits for multiplication binary polynomials\n",
    "\n",
    "![Circuits for polynomial multiplication](img/MultiplicationCircuits.png){width=90%}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Circuits for division binary polynomials\n",
    "\n",
    "![Circuits for polynomial division](img/DivisionCircuits.png){width=90%}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator polynomial\n",
    "\n",
    "**Theorem**: \n",
    "\n",
    "All the codewords of a cyclic code are multiples of a certain polynomial $g(x)$,\n",
    "known as **generator polynomial**. \n",
    "\n",
    "Properties of generator polynomial $g(x)$:\n",
    "\n",
    "* The generator polynomial has first and last coefficient equal to 1.\n",
    "* The generator polynomial is a factor of $X^n \\oplus 1$\n",
    "* The *degree* of $g(x)$ is $n-k$, where:\n",
    "    * The codeword = polynomial of degree $n-1$ ($n$ coefficients)\n",
    "    * The information polynomial = polynomial of degree $k-1$ ($k$ coefficients)\n",
    "$$ (k-1) + (n-k) = n-1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding a generator polynomial\n",
    "\n",
    "**Theorem**: \n",
    "\n",
    "If $g(x)$ is a polynomial of degree $(n-k)$ and is a factor of $X^n \\oplus 1$, \n",
    "then $g(x)$ generates a $(n,k)$ cyclic code\n",
    "\n",
    "Example:\n",
    "\n",
    "$$x^7 \\oplus 1 = (1 \\oplus X)(1 \\oplus X + \\oplus X^3)(1 \\oplus X^2 \\oplus X^3)$$\n",
    "\n",
    "Each factor generates a code:\n",
    "\n",
    "* $1 \\oplus X$ generates a (7,6) cyclic code\n",
    "* $1 \\oplus X \\oplus X^3$ generates a (7,4) cyclic code\n",
    "* $1 \\oplus X^2 \\oplus X^3$ generates a (7,4) cyclic code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the codewords\n",
    "\n",
    "**Non-systematic** codeword generation:\n",
    "\n",
    "* Codeword = information polynomial * $g(x)$\n",
    "\n",
    "$$\\boxed{c(x) = i(x) \\cdot g(x)}$$\n",
    "\n",
    "**Systematic** codeword generation:\n",
    "\n",
    "$$\\boxed{c(x) = b(x) \\oplus X^{n-k}i(x)}$$\n",
    "\n",
    "where $b(x)$ is the remainder of dividing $X^{n-k} i(x)$ to $g(x)$:\n",
    "$$X^{n-k} i(x) = a(x) g(x) \\oplus b(x)$$\n",
    "\n",
    "* (Proof: at blackboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cyclic code encoder circuits\n",
    "\n",
    "* Coding = based on polynomial multiplications and divisions\n",
    "* Efficient circuits for multiplication / division exist\n",
    "\n",
    "* Similar circuit exists for systematic codeword generation (draw on blackboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error detection with cyclic codes\n",
    "\n",
    "* Like usual for linear codes: check if received word is codeword or not\n",
    "\n",
    "* Every codeword is multiple of $g(x)$\n",
    "\n",
    "* Check if received word is actually dividing with $g(x)$\n",
    "    * Use a circuit for division of polynomials\n",
    "    \n",
    "* If remainder is 0 => it is a codeword, no error\n",
    "\n",
    "* If remainder is non-0 => error detected!\n",
    "\n",
    "* Cyclic codes have very good error detection capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error correction capability\n",
    "\n",
    "Theorem:\n",
    "\n",
    "Any (n,k) cyclic codes is capable of detecting any error **burst** of length $n-k$ or less.\n",
    "\n",
    "* A large fraction of longer bursts can also be detected (but not all)\n",
    "\n",
    "* For non-burst errors (random): more difficult to analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error correction with cyclic codes\n",
    "\n",
    "* Like usual for linear codes: lookup table based on remainder\n",
    "\n",
    "* Remainder of division = the effect of the error polynomial\n",
    "\n",
    "* Create lookup table: for every error word, compute remainder\n",
    "\n",
    "* Search the table for the remainder of the received word => find error word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of cyclic codes\n",
    "\n",
    "* Generated using a generator polynomial $g(x)$\n",
    "* Non-systematic:\n",
    "$$c(x) = i(x) \\cdot g(x)$$\n",
    "* Systematic:\n",
    "$$c(x) = b(x) \\oplus X^{n-k}i(x)$$\n",
    "    *  $b(x)$ is the remainder of dividing $X^{n-k} i(x)$ to $g(x)$\n",
    "* Syndrome = remainder of division $r(x)$ to $g(x)$\n",
    "* Error detection: remainder (syndrome) non-zero\n",
    "* Error correction: lookup table "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
